{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "GROUP_URL = 'https://www.facebook.com/groups/247152564671716'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'test-scraping.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h3 a[role='link']\")\n",
    "    if author_link:\n",
    "        details[\"author_name\"] = author_link[0].text\n",
    "        details[\"author_url\"] = author_link[0].get_attribute('href')\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[dir='auto']\")\n",
    "    if content_divs:\n",
    "        details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip())\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='/posts/'], span > a[role='link'][href*='?post_id=']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    footer = post_element.find_elements(By.CSS_SELECTOR, \"div[role='toolbar']\")\n",
    "    if footer:\n",
    "        reactions = footer[0].find_elements(By.CSS_SELECTOR, \"span[aria-label*='reaction']\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        \n",
    "        comments = footer[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    if details.get(\"author_name\") and details.get(\"post_content\"):\n",
    "        return details\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(GROUP_URL)\n",
    "\n",
    "        try:\n",
    "            email_input = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "            )\n",
    "            email_input.send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='feed']\")))\n",
    "        \n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 5, 0.5).until(\n",
    "                    lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                break\n",
    "        \n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\")\n",
    "                    f.write(f\"Author: {post.get('author_name', 'N/A')}\\n\")\n",
    "                    f.write(f\"Author URL: {post.get('author_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\")\n",
    "                    f.write(f\"Post URL: {post.get('post_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Reactions: {post.get('reactions', 'N/A')}\\n\")\n",
    "                    f.write(f\"Comments: {post.get('comments', 'N/A')}\\n\")\n",
    "                    f.write(\"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
